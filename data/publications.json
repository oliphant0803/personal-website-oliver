{
  "publications": [
    {
      "id": "ns",
      "titleShort": "Narrative Scaffolding",
      "type": "full paper",
      "selected": "yes",
      "title": "A Narrative-First Framework for Data-Driven Sensemaking",
      "venue": "IUI 2026",
      "authors": [
        "Oliver Huang",
        "Muhammad Fatir",
        "Steven Luo",
        "Sangho Suh",
        "Hari Subramonyam",
        "Carolina Nobre"
      ],
      "year": 2026,
      "links": {
        "arxiv": "https://arxiv.org/abs/2512.18920",
        "abs": "When exploring data, analysts construct narratives about what the data means by asking questions, generating visualizations, reflecting on patterns, and revising their interpretations as new insights emerge. Yet existing analysis tools treat narrative as an afterthought, breaking the link between reasoning, reflection, and the evolving story from exploration. Consequently, analysts lose the ability to see how their reasoning evolves, making it harder to reflect systematically or build coherent explanations. To address this gap, we propose Narrative Scaffolding, a framework for narrative-driven exploration that positions narrative construction as the primary interface for exploration and reasoning. We implement this framework in a system that externalizes iterative reasoning through narrative-first entry, semantically aligned view generation, and reflection support via insight provenance and inquiry tracking. In a within-subject study N=20, we demonstrate that narrative scaffolding facilitates broader exploration, deeper reflection, and more defensible narratives. An evaluation with visualization literacy experts (N = 6) confirmed that the system produced outputs aligned with narrative intent and facilitated intentional exploration."
      },
      "teaserImage": "/static/paper_image/2026/narrativeScaffolding.png",
      "tags": ["Data-driven Sensemaking", "Human-AI Interaction"]
    },
    {
      "id": "reflexis",
      "titleShort": "Reflexis",
      "type": "full paper",
      "selected": "yes",
      "title": "Supporting Reflexivity and Rigor in Collaborative Qualitative Analysis through Design for Deliberation",
      "venue": "CHI 2026",
      "authors": [
        "Runlong Ye",
        "Oliver Huang",
        "Patrick Lee",
        "Michael Liut",
        "Carolina Nobre",
        "Ha-Kyung Kong"
      ],
      "year": 2026,
      "links": {
        "demo": "https://scholar-mate-collab-2.vercel.app/",
        "abs": "Reflexive Thematic Analysis is a critical method for generating deep interpretive insights, yet its core tenets, including researcher reflexivity, productive disagreement, and transparent analytical evolution, are poorly supported by tools that prioritize speed and consensus over interpretive depth. To address this, we introduce Reflexive, a collaborative workspace that centers these practices. It supports reflexivity by integrating in-situ reflection prompts, makes code evolution transparent through a complete audit trail of analytical decisions, and scaffolds collaborative interpretation by turning differences into productive, positionality-aware dialogue. In a paired-analyst study (N=12), our results indicate that Reflexive successfully shifted participants toward more granular reflection and reframed disagreements as productive conversations. The evaluation also surfaced key design tensions, including desire for higher-level, networked memos and more user control over the timing of proactive alerts. Reflexive contributes a design framework for tools that prioritize rigor and transparency to support deep, collaborative interpretation in an age of automation."
      },
      "teaserImage": "/static/paper_image/2026/reflexis.png",
      "tags": ["Long-form Text", "Human-AI Interaction"]
    },
    {
      "id": "vistruct",
      "titleShort": "ViStruct",
      "type": "full paper",
      "selected": "yes",
      "title": "Simulating Expert-Like Reasoning Through Task Decomposition and Visual Attention Cues",
      "venue": "VIS 2025",
      "authors": [
        "Oliver Huang",
        "Carolina Nobre"
      ],
      "year": 2025,
      "links": {
        "arxiv": "https://arxiv.org/abs/2506.21762",
        "demo": "https://vi-struct.vercel.app/",
        "abs": "Data visualization tasks often require multi-step reasoning, and the interpretive strategies experts use—such as decomposing complex goals into smaller subtasks and selectively attending to key chart regions—are rarely made explicit. We developed ViStruct as an automated pipeline that simulates these expert behaviours by breaking high-level visual questions into structured analytic steps and highlighting semantically relevant chart areas. Leveraging large language and vision-language models, we evaluate the system on 45 tasks across 12 chart types and validate its outputs with trained visualization users, confirming its ability to produce interpretable and expert-aligned reasoning sequences."
      },
      "teaserImage": "/static/paper_image/2025/vistruct.png",
      "tags": ["Visualization Literacy", "Human-AI Interaction", "Education"]
    },
    {
      "id": "cognitive-engagement-techniques",
      "titleShort": "",
      "type": "full paper",
      "selected": "yes",
      "title": "Exploring the Design Space of Cognitive Engagement Techniques with AI-Generated Code for Enhanced Learning",
      "venue": "IUI 2025",
      "authors": [
        "Majeed Kazemi",
        "Oliver Huang",
        "Sangho Suh",
        "Austin Z. Henley",
        "Tovi Grossman"
      ],
      "year": 2025,
      "links": {
        "arxiv": "https://arxiv.org/abs/2410.08922",
        "demo": "https://majeedkazemi.github.io/code-engagement-techniques/",
        "abs": "Novice programmers are increasingly relying on Large Language Models (LLMs) to generate code for learning programming concepts. However, this interaction can lead to superficial engagement, giving learners an illusion of learning and hindering skill development. To address this issue, we conducted a systematic design exploration to develop seven cognitive engagement techniques aimed at promoting deeper engagement with AI-generated code. In this paper, we describe our design process, the initial seven techniques and results from a between-subjects study (N=82). We then iteratively refined the top techniques and further evaluated them through a within-subjects study (N=42). We evaluate the friction each technique introduces, their effectiveness in helping learners apply concepts to isomorphic tasks without AI assistance, and their success in aligning learners' perceived and actual coding abilities. Ultimately, our results highlight the most effective technique: guiding learners through the step-by-step problem-solving process, where they engage in an interactive dialog with the AI, prompting what needs to be done at each stage before the corresponding code is revealed."
      },
      "teaserImage": "/static/paper_image/2025/productiveFriction.png",
      "tags": ["Human-AI Interaction", "Education"]
    },
    {
      "id": "from-reality-to-recognition",
      "titleShort": "From Reality to Recognition",
      "type": "full paper",
      "selected": "yes",
      "title": "Evaluating Visualization Analogies for Novice Chart Comprehension",
      "venue": "EuroVis 2025",
      "authors": [
        "Oliver Huang",
        "Patrick Lee",
        "Carolina Nobre"
      ],
      "year": 2025,
      "links": {
        "arxiv": "https://arxiv.org/abs/2506.03385",
        "demo": "https://visanalogy.github.io/visualization-analogies/",
        "abs": "Novice learners often have difficulty learning new visualization types because they tend to interpret novel visualizations through the mental models of simpler charts they have previously encountered. Traditional visualization teaching methods, which usually rely on directly translating conceptual aspects of data into concrete data visualizations, often fail to attend to the needs of novice learners navigating this tension. To address this, we conducted an empirical exploration of how analogies can be used to help novices with chart comprehension. We introduced visualization analogies: visualizations that map data structures to real-world contexts to facilitate an intuitive understanding of novel chart types. We evaluated this pedagogical technique using a within-subject study (N=128) where we taught 8 chart types using visualization analogies. Our findings show that visualization analogies improve visual analysis skills and help learners transfer their understanding to actual charts. They effectively introduce visual embellishments, cater to diverse learning preferences, and are preferred by novice learners over traditional chart visualizations. This study offers empirical insights and open-source tools to advance visualization education through analogical reasoning."
      },
      "teaserImage": "/static/paper_image/2025/analogy.png",
      "tags": ["Visualization Literacy", "Education"]
    },
    {
      "id": "vis-poster-narrative-exploration",
      "titleShort": "",
      "type": "extended abstract",
      "selected": "no",
      "title": "Toward Supporting Narrative-Driven Data Exploration: Barriers and Design Opportunities",
      "venue": "VIS 2025",
      "authors": [
        "Oliver Huang",
        "Carolina Nobre"
      ],
      "year": 2025,
      "links": {
        "arxiv": "https://www.arxiv.org/abs/2508.04920",
        "poster": "https://www.canva.com/design/DAGrLvVvuDY/3Dx3-BMkcWLYcrcXOOuYfw/view?utm_content=DAGrLvVvuDY&utm_campaign=designshare&utm_medium=link2&utm_source=uniquelinks&utlId=h0ac8a2d2be"
      },
      "teaserImage": "/static/paper_image/2025/visplora.png",
      "tags": ["Human-AI Interaction", "Data-driven Sensemaking"]
    },
    {
      "id": "scholarmate",
      "titleShort": "ScholarMate",
      "type": "full paper",
      "selected": "no",
      "title": "A Mixed-Initiative Tool for Qualitative Knowledge Work and Information Sensemaking",
      "venue": "CHIWORK 2025",
      "authors": [
        "Runlong Ye",
        "Patrick Lee",
        "Matthew Varona",
        "Oliver Huang",
        "Carolina Nobre"
      ],
      "year": 2025,
      "links": {
        "arxiv": "https://arxiv.org/abs/2504.14406",
        "demo": "https://www.scholarmate.space/demo",
        "abs": "Synthesizing knowledge from large document collections is a critical yet increasingly complex aspect of qualitative research and knowledge work. While AI offers automation potential, effectively integrating it into human-centric sensemaking workflows remains challenging. We present ScholarMate, an interactive system designed to augment qualitative analysis by unifying AI assistance with human oversight. ScholarMate enables researchers to dynamically arrange and interact with text snippets on a non-linear canvas, leveraging AI for theme suggestions, multi-level summarization, and evidence-based theme naming, while ensuring transparency through traceability to source documents. Initial pilot studies indicated that users value this mixed-initiative approach, finding the balance between AI suggestions and direct manipulation crucial for maintaining interpretability and trust. We further demonstrate the system's capability through a case study analyzing 24 papers. By balancing automation with human control, ScholarMate enhances efficiency and supports interpretability, offering a valuable approach for productive human-AI collaboration in demanding sensemaking tasks common in knowledge work."
      },
      "teaserImage": "/static/paper_image/2025/scholarmate.png",
      "tags": ["Human-AI Interaction", "Data-driven Sensemaking", "Long-form Text"]
    },
    {
      "id": "treereader",
      "titleShort": "TreeReader",
      "type": "full paper",
      "selected": "no",
      "title": "A Hierarchical Academic Paper Reader Powered by Language Models",
      "venue": "VL/HCC 2025",
      "authors": [
        "Zijian Zhang", "Pan Chen", "Fangshi Du", "Runlong Ye", "Oliver Huang", "Michael Liut", "Alán Aspuru-Guzik"
      ],
      "year": 2025,
      "links": {
        "arxiv": "https://arxiv.org/abs/2507.18945",
        "demo": "https://www.treer.ai/",
        "abs": "Efficiently navigating and understanding academic papers is crucial for scientific progress. Traditional linear formats like PDF and HTML can cause cognitive overload and obscure a paper's hierarchical structure, making it difficult to locate key information. While LLM-based chatbots offer summarization, they often lack nuanced understanding of specific sections, may produce unreliable information, and typically discard the document's navigational structure. Drawing insights from a formative study on academic reading practices, we introduce TreeReader, a novel language model-augmented paper reader. TreeReader decomposes papers into an interactive tree structure where each section is initially represented by an LLM-generated concise summary, with underlying details accessible on demand. This design allows users to quickly grasp core ideas, selectively explore sections of interest, and verify summaries against the source text. A user study was conducted to evaluate TreeReader's impact on reading efficiency and comprehension. TreeReader provides a more focused and efficient way to navigate and understand complex academic literature by bridging hierarchical summarization with interactive exploration."
      },
      "teaserImage": "/static/paper_image/2025/treereader.png",
      "tags": ["Human-AI Interaction", "Long-form Text"]
    },
    {
      "id": "treewriter",
      "titleShort": "TreeWriter",
      "type": "full paper",
      "selected": "no",
      "title": "AI-Assisted Hierarchical Planning and Writing for Long-Form Documents",
      "venue": "ArXiv",
      "authors": [
        "Zijian Zhang", 
        "Fangshi Du", "Xingjian Liu", "Pan Chen", "Oliver Huang", "Runlong Ye", "Michael Liut", "Alán Aspuru-Guzik"
      ],
      "year": 2026,
      "links": {
        "arxiv": "https://www.arxiv.org/abs/2601.12740",
        "demo": "https://www.treer.ai/",
        "abs": "Efficiently navigating and understanding academic papers is crucial for scientific progress. Traditional linear formats like PDF and HTML can cause cognitive overload and obscure a paper's hierarchical structure, making it difficult to locate key information. While LLM-based chatbots offer summarization, they often lack nuanced understanding of specific sections, may produce unreliable information, and typically discard the document's navigational structure. Drawing insights from a formative study on academic reading practices, we introduce TreeReader, a novel language model-augmented paper reader. TreeReader decomposes papers into an interactive tree structure where each section is initially represented by an LLM-generated concise summary, with underlying details accessible on demand. This design allows users to quickly grasp core ideas, selectively explore sections of interest, and verify summaries against the source text. A user study was conducted to evaluate TreeReader's impact on reading efficiency and comprehension. TreeReader provides a more focused and efficient way to navigate and understand complex academic literature by bridging hierarchical summarization with interactive exploration."
      },
      "teaserImage": "/static/paper_image/2026/treewriter.png",
      "tags": ["Human-AI Interaction", "Long-form Text"]
    },
    {
      "id": "aiattribution",
      "titleShort": "Which Code Counts as Mine?",
      "type": "extended abstract",
      "selected": "no",
      "title": " Perceptions of AI Attribution in Programming Education",
      "venue": "CHI 2026",
      "authors": [
        "Runlong Ye",
        "Oliver Huang",
        "Jessica He",
        "Michael Liut"
      ],
      "year": 2026,
      "links": {
        "abs": "Generative AI is rapidly transforming computing education, yet norms for attributing AI assistance remain unsettled. While universities emphasize transparency, it is unclear how students actually navigate these ethical decisions when code generation, debugging, and refinement are intertwined. To understand these attribution behaviors, we conducted a study with 94 computer science students, analyzing their perceptions across 102 scenarios varying by assessment type, AI autonomy, and human refinement effort. Our analysis reveals that students’ attribution judgments are not shaped by the type of assignment, but primarily by the mechanics of interaction: the level of AI assistance and the subsequent human effort to refine the AI output. As AI tools become more autonomous, students perceive a sharp decline in their own ownership and learning value, leading to demands for stricter institutional disclosure policies. However, a critical gap emerged between principle and practice. While students believe policies should be based on fairness and contribution, their personal decisions to disclose are often disconnected from these factors, likely driven by risk aversion rather than academic integrity. These findings suggest that the current standard “citation-style” policies are insufficient for programming courses. Rather than simply policing whether a tool was used, we propose a shift toward process-oriented attribution. Effective guidelines should require students to document how they verified and modified AI-generated outputs, transforming attribution from a compliance check into a pedagogical tool that assesses the student’s ability to evaluate and refine code."
      },
      "teaserImage": "/static/paper_image/2026/aiAttribution.png",
      "tags": ["Human-AI Interaction", "Education"]
    }
  ]
}
